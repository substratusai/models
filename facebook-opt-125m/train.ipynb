{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94897417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PromptData import PromptData\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import torch\n",
    "from infer import Inferer\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14752812",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.environ['DATA_PATH']\n",
    "\n",
    "tokenizer = torch.load('/built/tokenizer.pt')\n",
    "model = torch.load('/built/model.pt')\n",
    "\n",
    "ds = PromptData(data_path, tokenizer)\n",
    "# TODO: Grab batch sizefrom configuration.\n",
    "dl = DataLoader(ds, batch_size=1)\n",
    "\n",
    "# TODO: Grab from configuration.\n",
    "epochs = 3\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dat, model, optim):\n",
    "    for i in tqdm.tqdm(range(epochs)):\n",
    "        for X, a in dat:\n",
    "            X = X.to(device)\n",
    "            a = a.to(device)\n",
    "            optim.zero_grad()\n",
    "            loss = model(X, attention_mask=a, labels=X).loss\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        #torch.save(model.state_dict(), \"model_state.pt\")\n",
    "\n",
    "print(\"training .... \")\n",
    "model.train()\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "train(dl, model, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/trained/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c020c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Inferer(model, tokenizer, device).infer(\"What is your favorite color?\", 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
